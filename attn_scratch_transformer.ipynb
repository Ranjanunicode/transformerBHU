{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNe5vxpo99Caj5VR8x9x0kK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ranjanunicode/transformerBHU/blob/main/attn_scratch_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExnoTRlm0hEm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(z):\n",
        "  z=np.exp(z-z.max(axis=-1, keepdims=True))\n",
        "  return z / z.sum(axis=-1, keepdims=True)\n",
        "\n",
        "def self_attention(X, mask, W_KQV, W_out):\n",
        "  K,Q,V = np.split(X@W_KQV, 3, axis=1)\n",
        "  attn = softmax(K@Q.T / np.sqrt(X.shape[1]) + mask)\n",
        "  return attn@V@W_out, attn\n"
      ],
      "metadata": {
        "id": "mxTpKy1g2ce4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T, d = 100, 64\n",
        "attn = nn.MultiheadAttention(d, 1, bias=False, batch_first=True)\n",
        "M = torch.triu(-float(\"inf\")*torch.ones(T,T),1)\n",
        "X = torch.randn(1,T,d)\n",
        "Y_, A_ = attn(X, X, X, attn_mask=M)"
      ],
      "metadata": {
        "id": "pzevrSXJ3ywV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn.out_proj.weight.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71HNHxYP5QA1",
        "outputId": "02bb6060-2ef1-45cd-fd89-842829972f35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y, A = self_attention(X[0].numpy(),\n",
        "                      M.numpy(),\n",
        "                      attn.in_proj_weight.detach().numpy().T,\n",
        "                      attn.out_proj.weight.detach().numpy().T)"
      ],
      "metadata": {
        "id": "B8TxRy1b4yGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.linalg.norm(A - A_[0].detach().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P55zkIh57lH",
        "outputId": "06cbe6b6-c30b-490c-bd37-b47b354ad6de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.2423544e-07"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Minibatching"
      ],
      "metadata": {
        "id": "QwSIzP9J7yYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C = np.random.randn(5,4,10,3)\n",
        "D = np.random.randn(3,6)\n",
        "(C@D).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laNKkUve71So",
        "outputId": "ccfba1aa-8484-413d-ef67-d6fc0bd2c2e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 4, 10, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (C.reshape(-1,3) @ D).reshape(5,4,10,6)\n",
        "def self_attention(X, mask, W_KQV, W_out):\n",
        "  K,Q,V = np.split(X@W_KQV, 3, axis=-1)\n",
        "  attn = softmax(K@Q.swapaxes(-1,-2) / np.sqrt(X.shape[-1]) + mask)\n",
        "  return attn@V@W_out, attn"
      ],
      "metadata": {
        "id": "FaABYoev-Bi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B, T, d = 50, 100, 64\n",
        "X = torch.randn(B,T,d)\n",
        "M = torch.triu(-float(\"inf\")*torch.ones(T,T),1)\n",
        "Y_, A_ = attn(X, X, X, attn_mask=M)"
      ],
      "metadata": {
        "id": "ZmDSxW6h_IIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y, A = self_attention(X.numpy(),\n",
        "                      M.numpy(),\n",
        "                      attn.in_proj_weight.detach().numpy().T,\n",
        "                      attn.out_proj.weight.detach().numpy().T)"
      ],
      "metadata": {
        "id": "OIfxAQ9F_Jlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.linalg.norm(A - A_.detach().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT2Q2D_j_uf3",
        "outputId": "37bfcb7e-6bf5-4bda-f08e-5502ccd56f6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.5895062e-06"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multihead attention"
      ],
      "metadata": {
        "id": "xhmi3N3Y_7kv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cr6tYBDi_6ax"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}